{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "2018-11-29 18:36:43,634 - matplotlib - DEBUG - CACHEDIR=/home/ubuntu/.cache/matplotlib\n",
      "2018-11-29 18:36:43,638 - matplotlib.font_manager - DEBUG - Using fontManager instance from /home/ubuntu/.cache/matplotlib/fontList.json\n",
      "2018-11-29 18:36:43,718 - matplotlib.backends - DEBUG - backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/MLMortgage/src/data', '', '/home/ubuntu/src/cntk/bindings/python', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python36.zip', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/lib-dynload', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages', '/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/extensions', '/home/ubuntu/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 18:36:43,785 - matplotlib.backends - DEBUG - backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import psutil\n",
    "import numpy as np\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import glob\n",
    "from tensorflow.python.framework import ops\n",
    "import math\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import ftplib\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "nb_dir = os.path.join(Path(os.getcwd()).parents[0], 'src', 'data')\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.insert(0, nb_dir)\n",
    "print(sys.path)\n",
    "import features_selection as fs\n",
    "import make_dataset as md\n",
    "import build_data as bd\n",
    "import get_raw_data as grd\n",
    "\n",
    "models_dir = os.path.join(Path(os.getcwd()).parents[0], 'src', 'models')\n",
    "if models_dir not in sys.path:\n",
    "    sys.path.insert(0, models_dir)\n",
    "import nn_real as nn\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pd.set_option('io.hdf.default_format','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/MLMortgage/data/raw /home/ubuntu/MLMortgage/data/processed\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "RAW_DIR = os.path.join(Path(os.getcwd()).parents[0], 'data', 'raw') \n",
    "PRO_DIR = os.path.join(Path(os.getcwd()).parents[0], 'data', 'processed')\n",
    "RANDOM_SEED = 123  # Set the seed to get reproducable results.\n",
    "DT_FLOAT = np.float32\n",
    "NP_FLOAT = np.dtype('float32')\n",
    "\n",
    "train_dir = 'chuncks_random_c1millx2_train' # 'chuncks_random_1th_train'\n",
    "valid_dir = 'chuncks_random_c1millx2_valid' # 'chuncks_random_1th_valid'\n",
    "test_dir = ''\n",
    "train_period=[121,323] #[121,279] #[121, 143] \n",
    "valid_period=[324,329] #[280,285] #[144, 147] \n",
    "test_period=[330,342] #[286,304] #[148, 155]\n",
    "batch_size=50000\n",
    "\n",
    "\n",
    "print(RAW_DIR, PRO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_dict(train_dir, valid_dir, test_dir):        \n",
    "    ext = \"*.h5\"\n",
    "\n",
    "    files_dict = {'train': glob.glob(os.path.join(PRO_DIR, train_dir, ext)), \n",
    "                  'valid': glob.glob(os.path.join(PRO_DIR, valid_dir, ext)), \n",
    "                  'test': glob.glob(os.path.join(PRO_DIR, test_dir, ext))}\n",
    "\n",
    "    return files_dict\n",
    "\n",
    "def architecture_settings(files_dict):\n",
    "    architecture = {}    \n",
    "    ok_inputs = True\n",
    "    \n",
    "    for key in files_dict.keys():\n",
    "        total_records = 0\n",
    "        for file in files_dict[key]:                                \n",
    "            with pd.HDFStore(file) as dataset_file:\n",
    "                if (ok_inputs): \n",
    "                    index_length = len(dataset_file.get_storer(key+'/features').attrs.data_columns)\n",
    "                    architecture['n_input'] = dataset_file.get_storer(key+ '/features').ncols - index_length\n",
    "                    architecture['n_classes'] = dataset_file.get_storer(key+'/labels').ncols - index_length\n",
    "                    ok_inputs = False                \n",
    "                total_records += dataset_file.get_storer(key + '/features').nrows\n",
    "        architecture[key + '_num_examples'] = total_records                            \n",
    "    \n",
    "    architecture['total_num_examples'] = architecture['train_num_examples'] # 10000000\n",
    "    return architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_input': 258, 'n_classes': 7, 'train_num_examples': 26769588, 'valid_num_examples': 901868, 'test_num_examples': 0, 'total_num_examples': 26769588}\n"
     ]
    }
   ],
   "source": [
    "#To sum up the dataset per worker (assuming the same size of files per worker approximately):\n",
    "files_dict = get_files_dict(train_dir, valid_dir, test_dir)\n",
    "architecture = architecture_settings(files_dict)\n",
    "print(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving into another .h5 dataset:\n",
    "def remove_label(tag, label_todel, file_dir, fname):    \n",
    "    all_files = glob.glob(os.path.join(PRO_DIR, file_dir, \"*.h5\"))\n",
    "    file_name = fname + tag + '_.h5'\n",
    "    target_path = os.path.join(PRO_DIR, file_dir, file_name)          \n",
    "    with pd.HDFStore(target_path, complib='lzo', complevel=9) as hdf_target:\n",
    "        print('Target Path: ', target_path)   \n",
    "        # idxs = np.resize(drop_cols.values(),np.count_nonzero(drop_cols.values()))                \n",
    "        # print('columns dropped')\n",
    "        acc_rows = 0        \n",
    "        total_files = len(all_files)            \n",
    "        lab_classes = ['0', '3', '6', '9', 'C', 'F', 'R']\n",
    "        total_num_examples = 0        \n",
    "        for i, file_path in zip(range(total_files), all_files):    \n",
    "            with pd.HDFStore(file_path) as dataset_file:                                \n",
    "                print(file_path, '...to load')\n",
    "                #columns = dataset_file.get_storer(dtype+'/labels').attrs.non_index_axes[0][1]\n",
    "                total_records_file=0\n",
    "                for nclass in (set(lab_classes) - set(label_todel)):\n",
    "                    print('class No.: ', nclass)                       \n",
    "                    class_features = dataset_file.select(tag+'/features',  \"index=='\"+ str(nclass) + \"'\")                    \n",
    "                    class_features = class_features.astype(DT_FLOAT)\n",
    "                    class_labels = dataset_file.select(tag+'/labels',  \"index=='\"+ str(nclass) + \"'\")\n",
    "                    class_labels.drop('DELINQUENCY_STATUS_NEXT_'+label_todel, axis=1, inplace=True)\n",
    "                    class_labels = class_labels.astype(np.int8)\n",
    "                    total_rows = len(class_labels.values)\n",
    "                    hdf_target.put(tag + '/features', class_features, append=True) \n",
    "                    hdf_target.put(tag + '/labels', class_labels, append=True) \n",
    "                    hdf_target.flush()\n",
    "                    print(file_path, ' class ', nclass,': saved in disk, nrows: ', total_rows, 'labcols: ', class_labels.shape[1])                                                            \n",
    "                    total_num_examples += total_rows                    \n",
    "                                    \n",
    "        print('total_num_examples: ', total_num_examples)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Path:  /home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/dataset_non_current_train_.h5\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5 ...to load\n",
      "class No.:  6\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  6 : saved in disk, nrows:  259623 labcols:  6\n",
      "class No.:  9\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  9 : saved in disk, nrows:  614496 labcols:  6\n",
      "class No.:  R\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  R : saved in disk, nrows:  27885 labcols:  6\n",
      "class No.:  F\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  F : saved in disk, nrows:  499157 labcols:  6\n",
      "class No.:  3\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  3 : saved in disk, nrows:  736172 labcols:  6\n",
      "class No.:  0\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_train/temporalloandynmodifmrstaticitur15mill-16mill-train_0.h5  class  0 : saved in disk, nrows:  445264 labcols:  6\n",
      "total_num_examples:  2582597\n"
     ]
    }
   ],
   "source": [
    "label_todel = 'C'\n",
    "remove_label('train', label_todel, train_dir, '_dataset_non_current_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Path:  /home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/dataset_non_current_valid_.h5\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5 ...to load\n",
      "class No.:  6\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  6 : saved in disk, nrows:  6681 labcols:  6\n",
      "class No.:  9\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  9 : saved in disk, nrows:  15002 labcols:  6\n",
      "class No.:  R\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  R : saved in disk, nrows:  410 labcols:  6\n",
      "class No.:  F\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  F : saved in disk, nrows:  9960 labcols:  6\n",
      "class No.:  3\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  3 : saved in disk, nrows:  19805 labcols:  6\n",
      "class No.:  0\n",
      "/home/ubuntu/MLMortgage/data/processed/chuncks_random_c1millx2_valid/temporalloandynmodifmrstaticitur15mill-16mill-valid_0.h5  class  0 : saved in disk, nrows:  14560 labcols:  6\n",
      "total_num_examples:  66418\n"
     ]
    }
   ],
   "source": [
    "remove_label('valid', label_todel, valid_dir, '_dataset_non_current_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
