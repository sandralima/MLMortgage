{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting raw data from Mercury ftp server\n",
    "you need to download the raw data and save it at /home/ubuntu/MLMortgage/data/raw/[raw_directory]\n",
    "For this example [raw_directory]='chuncks_random_c1mill'. If it does not exist, the wget command will created it.\n",
    "you can change the example file 'temporalloandynmodifmrstaticitu-random-1mill-2mill.txt' for the desired file.\n",
    "Note: This works only for ubuntu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --ftp-user=machinelearning --ftp-password=Mdje7i3739# ftp://mercury.vichara.co.uk/temporalloandynmodifmrstaticitu-random-1mill-2mill.txt -P /home/ubuntu/MLMortgage/data/raw/chuncks_random_c1mill/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import psutil\n",
    "\n",
    "nb_dir = os.path.join(Path(os.getcwd()).parents[0], 'src', 'data')\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.insert(0, nb_dir)\n",
    "# print(sys.path)\n",
    "import features_selection as fs\n",
    "import make_dataset as md\n",
    "import build_data as bd\n",
    "import get_raw_data as grd\n",
    "import data_classes\n",
    "import glob\n",
    "\n",
    "models_dir = os.path.join(Path(os.getcwd()).parents[0], 'src', 'models')\n",
    "if models_dir not in sys.path:\n",
    "    sys.path.insert(0, models_dir)\n",
    "import nn_real as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = os.path.join(Path(os.getcwd()).parents[0], 'data', 'raw') \n",
    "PRO_DIR = os.path.join(Path(os.getcwd()).parents[0], 'data', 'processed')\n",
    "\n",
    "print(RAW_DIR, PRO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing  \n",
    "From console you can run:\n",
    "\n",
    "#### $ cd /home/ubuntu/MLMortgage/src/data\n",
    "\n",
    "#### $ python build_data.py --prepro_step=preprocessing --prepro_dir=chuncks_random_c1mill --prepro_chunksize=500000 --train_period 121 143 --valid_period 144 147 --test_period 148 155\n",
    "\n",
    "\n",
    "For this example, the raw file will be extracted from 'data/raw/chuncks_random_c1mill' directory  and the processed file will be save at 'data/processed/chuncks_random_c1mill' according to the folder name that you give in the parameter --prepro_dir. The periods are defined for training, validation and testing. prepro_chunksize is a parameter for processing blocks of data, instead just one by one. In this implementation the preprocessed file will be save in .h5 format because of their compression format and also you can put training, validation and testing dataset in just one file.\n",
    "\n",
    "The following cells make the same as in console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS, UNPARSED = bd.update_parser(argparse.ArgumentParser())    \n",
    "#these are the more important parameters for preprocessing:\n",
    "FLAGS.prepro_dir='chuncks_random_c1mill' #this directory must be the same inside 'raw' and processed directories.\n",
    "FLAGS.prepro_chunksize=500000 \n",
    "FLAGS.train_period=[121,279] #[121, 143] \n",
    "FLAGS.valid_period=[280,285] #[144, 147] \n",
    "FLAGS.test_period=[286,304] #[148, 155]\n",
    "                                                \n",
    "print(FLAGS)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(os.path.join(RAW_DIR, FLAGS.prepro_dir,\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "if not os.path.exists(os.path.join(PRO_DIR, FLAGS.prepro_dir)): #os.path.exists\n",
    "        os.makedirs(os.path.join(PRO_DIR, FLAGS.prepro_dir))\n",
    "bd.allfeatures_preprocessing(RAW_DIR, PRO_DIR, FLAGS.prepro_dir, FLAGS.train_period, FLAGS.valid_period, FLAGS.test_period, dividing='percentage', \n",
    "                          chunksize=FLAGS.prepro_chunksize, refNorm=FLAGS.ref_norm, with_index=FLAGS.prepro_with_index, output_hdf=True)        \n",
    "print('Preprocessing - Time: ', datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/ubuntu/MLMortgage/src/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first h5 file:\n",
    "!python build_data.py --prepro_step=slicing --slice_input_dir=chuncks_random_c1mill --slice_output_dir chuncks_random_c1millx2_train chuncks_random_c1millx2_valid chuncks_random_c1millx2_test --slice_tag train valid test --slice_target_name 1-1mill_cs1200_train 1-11mill_cs1200_valid 1-1mill_cs1200_test --slice_target_size=36000000 --slice_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd. h5 file:\n",
    "!python build_data.py --prepro_step=slicing --slice_input_dir=chuncks_random_c1mill --slice_output_dir chuncks_random_c1millx2_train chuncks_random_c1millx2_valid chuncks_random_c1millx2_test --slice_tag train valid test --slice_target_name 2mill-3mill_cs1200_train 2mill-3mill_cs1200_valid 2mill-3mill_cs1200_test --slice_target_size=36000000 --slice_index=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "From console, execute:\n",
    "\n",
    "#### $ cd /home/ubuntu/MLMortgage/src/models\n",
    "\n",
    "#### $ python nn_real.py --train_dir=chuncks_random_c1mill --valid_dir=chuncks_random_c1mill --test_dir=chuncks_random_c1mill --logdir=/home/ubuntu/real_summaries_4425_-15ep_99-01/ --epoch_num=15 --max_epoch_size=-1 --batch_size=4425                                                    \n",
    "This execution runs 15 epochs over the entire dataset (max_epoch_size=-1) and the training, validation and testing datasets are in the same directory inside /home/ubuntu/MLMortgage/data/processed/chuncks_random_c1mill/. \n",
    "\n",
    "The checkpoints and the models results will be saved into, for example, logdir=/home/ubuntu/real_summaries_4425_-15ep_99-01/. You can change it by uncommenting and modifying the FLAGS.logdir variable.\n",
    "\n",
    "To execute step by step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "FLAGS, UNPARSED = nn.update_parser(argparse.ArgumentParser())\n",
    "print(\"UNPARSED\", UNPARSED)\n",
    "FLAGS.logdir=Path(str('/home/ubuntu/real_summaries4425-15ep_test/'))\n",
    "if not os.path.exists(os.path.join(FLAGS.logdir)): #os.path.exists\n",
    "    os.makedirs(os.path.join(FLAGS.logdir))\n",
    "FLAGS = nn.FLAGS_setting(FLAGS, 1)\n",
    "FLAGS.train_dir = 'chuncks_random_c1millx2_train'\n",
    "FLAGS.valid_dir = 'chuncks_random_c1millx2_valid'\n",
    "FLAGS.test_dir = 'chuncks_random_c1millx2_test'\n",
    "FLAGS.train_period=[121,279] #[121, 143] \n",
    "FLAGS.valid_period=[280,285] #[144, 147] \n",
    "FLAGS.test_period=[286,304] #[148, 155]\n",
    "FLAGS.epoch_num=15 \n",
    "FLAGS.max_epoch_size=-1 \n",
    "FLAGS.batch_size=4425\n",
    "print(\"FLAGS\", FLAGS) #you can change the FLAGS by adding the setting before this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = md.get_h5_data(PRO_DIR, FLAGS.train_dir, FLAGS.valid_dir, FLAGS.test_dir, train_period=FLAGS.train_period, valid_period=FLAGS.valid_period, test_period=FLAGS.test_period) \n",
    "print('Features List: ', DATA.train.features_list)\n",
    "print('Labels List: ', DATA.train.labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FLAGS.log_file.write('METRICS:  %s\\r\\n' % str(FLAGS))\n",
    "FLAGS.log_file.write('training files:  %s\\r\\n' % str(DATA.train._dict))\n",
    "# print('training files:  %s\\r\\n' % str(DATA.train._dict))\n",
    "FLAGS.log_file.write('validation files:  %s\\r\\n' % str(DATA.validation._dict))\n",
    "# print('validation files:  %s\\r\\n' % str(DATA.validation._dict))\n",
    "FLAGS.log_file.write('testing files:  %s\\r\\n' % str(DATA.test._dict))        \n",
    "# print('testing files:  %s\\r\\n' % str(DATA.test._dict))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training features - Sample', DATA.train._dict[0]['dataset_features'][0:100]) #you can increase the sampling number of records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = nn.architecture_settings(DATA, FLAGS)\n",
    "print('RAM before build: ', psutil.virtual_memory()) #  physical memory usage\n",
    "FLAGS.log_file.write('RAM  before build: %s\\r\\n' % str(psutil.virtual_memory()))\n",
    "graph = nn.build_graph(architecture, FLAGS)        \n",
    "print('RAM after build', psutil.virtual_memory()) #  physical memory usage\n",
    "FLAGS.log_file.write('RAM  after build: %s\\r\\n' % str(psutil.virtual_memory()))\n",
    "nn.run_model(graph, 'testing_data', 1,  FLAGS, DATA)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
